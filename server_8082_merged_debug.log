DEBUG: CMS MODULE LOADED FROM /home/craigm26/Downloads/ContinuonXR/continuonbrain/hope_impl/cms.py
[DEBUG] server_routes imported from: /home/craigm26/Downloads/ContinuonXR/continuonbrain/server/routes.py
  Detected Hailo AI HAT+ (1 device(s)) - enabling offloading
  CONTINUON_PREFER_JAX=1 and JAX detected -> Enforcing JAX chat init.
JAX not available - install with: pip install jax jaxlib flax
JAX or transformers not available - cannot create GemmaChatJAX
HUGGINGFACE_TOKEN not set - gated models will not be accessible
  [Startup] Pre-loading model checkpoints...
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:02<00:05,  2.96s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:04<00:01,  1.88s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.27s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]
  [Startup] Model load result: True
 Model selected: JAX CoreModel (backend=jax)
  Failed to start status endpoint: [Errno 98] Address already in use
Initializing Robot Service (MOCK MODE)...

 Initializing episode recorder...
Using MOCK hardware mode
  Using mock microphone capture
Microphone capture initialized
 Episode recorder ready
  Skipping arm/drivetrain init (skip-motion-hw). Motion will stay mock.
 Initializing mode manager...
  Returning to idle...
============================================================
 Mode Change: idle -> idle
============================================================
Time: 2025-12-14 22:15:51
Motion: Disabled
Recording: OFF
Inference: OFF
Self-Training: OFF
============================================================

 Mode manager ready
 Chat-learn scheduler: Merged into autonomous supervisor (independent thread disabled).
 HOPE autonomous learner supervisor started (thread; mode-gated)[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False

 Autonomy orchestrator started (thread; resource-aware)

============================================================
 Robot Service Ready (MOCK MODE)
============================================================

Web UI: http://localhost:8082/ui
API Endpoint: http://localhost:8082/status
Resource level changed: normal -> warning: WARNING: Memory at 95.3% - 381MB available
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /
[HTTP] GET /api/camera/stream
[HTTP] GET /static/ui.css
[HTTP] GET /static/client.js
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /static/chat-overlay.js
[HTTP] GET /static/mobile-shell.js
[HTTP] GET /api/status
[HTTP] GET /api/training/architecture_status
Resource level changed: warning -> normal: Normal: 464MB available (94.2% used)
Resource level changed: normal -> warning: WARNING: Memory at 95.3% - 378MB available
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/system/events
[HTTP] GET /api/training/status
[HTTP] GET /api/training/metrics
[HTTP] GET /api/training/data_quality
[HTTP] GET /api/training/tool_dataset_summary
Resource level changed: warning -> normal: Normal: 486MB available (94.0% used)
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/tasks
[HTTP] GET /api/skills
[HTTP] GET /api/training/cloud_readiness
[HTTP] GET /api/status
[HTTP] GET /api/training/eval_summary
[HTTP] GET /api/training/status
[HTTP] GET /api/training/data_quality
[HTTP] GET /api/training/architecture_status
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/training/tool_dataset_summary
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
Resource level changed: normal -> warning: WARNING: Memory at 95.3% - 377MB available
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/tasks
[HTTP] GET /api/training/metrics
[HTTP] GET /api/status
[HTTP] POST /api/training/control/mode
[HTTP] GET /api/system/events
[HTTP] GET /api/training/status
[HTTP] GET /api/training/eval_summary
[HTTP] GET /api/skills
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/training/cloud_readiness
[HTTP] GET /api/training/status
[HTTP] GET /api/status
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/training/status
[HTTP] GET /api/training/status
[HTTP] GET /api/training/metrics
[HTTP] GET /api/training/eval_summary
[HTTP] GET /api/training/data_quality
[HTTP] GET /api/training/tool_dataset_summary
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/tasks
[HTTP] GET /api/training/architecture_status
Resource level changed: warning -> normal: Normal: 2031MB available (74.8% used)
[HTTP] GET /api/system/events
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/skills
[HTTP] GET /api/training/cloud_readiness
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/status
[HTTP] GET /api/training/eval_summary
[HTTP] GET /api/training/data_quality
[HTTP] GET /api/training/tool_dataset_summary
[HTTP] GET /api/tasks
[HTTP] GET /api/training/status
[HTTP] GET /api/training/metrics
[HTTP] GET /api/status
[HTTP] GET /api/skills
[HTTP] GET /api/training/architecture_status
[HTTP] GET /api/training/cloud_readiness
[HTTP] GET /api/training/status
[HTTP] GET /api/status
[HTTP] GET /api/system/events
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/status
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/status
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/training/status
[HTTP] GET /api/training/status
[HTTP] GET /api/training/metrics
[HTTP] GET /api/training/eval_summary
[HTTP] GET /api/training/data_quality
[HTTP] GET /api/training/tool_dataset_summary
[DEBUG Auto] mode=idle, want_run=False, chat_enabled=True, due=True, rec=False
[HTTP] GET /api/tasks
[HTTP] GET /api/skills
[HTTP] GET /api/training/architecture_status
[HTTP] GET /api/mobile/summary
[HTTP] POST /api/mode/autonomous
============================================================
 Mode Change: idle -> autonomous
============================================================
Time: 2025-12-14 22:17:07
Motion: Enabled
Recording: ON
Inference: ON
Self-Training: OFF

Mode Configuration:
  control_source: vla_policy
============================================================

[HTTP] GET /api/status
[HTTP] GET /api/system/events
[HTTP] GET /api/training/cloud_readiness
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/status
[ChatAdapter] chat() called with model_hint=None delegate=None
DEBUG_CMS_INIT: d_s=128, d_e=128, d_k=32, d_c=128, num_levels=3, cms_dims=[64, 128, 256]
[DEBUG Auto] mode=autonomous, want_run=True, chat_enabled=True, due=True, rec=False
[UnifiedAgent] Pausing Controller for Chat Session...
[UnifiedAgent] Starting Chat Learning Session...
[DEBUG] RunChatLearn called. Turns=20, Model=hope-v1, Delegate=google/gemma-370m
[DEBUG] RunChatLearn: Starting loop for 20 turns. LogRLDS=True
[DEBUG] Loop 0: History=0, Outputs=0
[ChatAdapter] chat() called with model_hint=hope-v1 delegate=google/gemma-370m
Ignoring model_hint=google/gemma-370m because it is not present in local HF cache (/home/craigm26/.cache/huggingface/hub) and downloads are disabled.
[HTTP] GET /api/status
[HTTP] GET /api/status
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/training/status
[HTTP] GET /api/training/metrics
[HTTP] GET /api/training/eval_summary
[HTTP] GET /api/training/data_quality
[HTTP] GET /api/training/tool_dataset_summary
[HTTP] GET /api/tasks
[HTTP] GET /api/skills
[HTTP] GET /api/training/architecture_status
[HTTP] GET /api/system/events
[HTTP] GET /api/mobile/summary
[HTTP] GET /api/training/cloud_readiness
[HTTP] GET /api/status
[HTTP] POST /api/chat
[ChatAdapter] chat() called with model_hint=None delegate=google/gemma-370m
Ignoring model_hint=google/gemma-370m because it is not present in local HF cache (/home/craigm26/.cache/huggingface/hub) and downloads are disabled.
