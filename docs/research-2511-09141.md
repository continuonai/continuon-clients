# Research Note: arXiv 2511.09141 — Recurrent Geometric-prior Multimodal Policy (RGMP)

## Paper Overview
RGMP proposes an end-to-end humanoid manipulation framework that couples geometric-semantic skill planning with data-efficient visuomotor control. The approach combines a **Geometric-prior Skill Selector (GSS)** that injects shape/affordance priors into a vision-language model for skill dispatch, and an **Adaptive Recursive Gaussian Network (ARGN)** that encodes multi-scale spatial relationships with rotary position embeddings, adaptive decay, and Gaussian Mixture Models for action decoding. The system reports 87% success on generalization tests with roughly 5× lower data requirements than Diffusion Policy, using only ~40 demonstrations per skill.

## Key Constructs and Signals
- **Modalities**: RGB images with bounding boxes and optional instance segmentation masks; natural-language commands; joint-space trajectories (6-DoF) for manipulation execution.
- **GSS (planning loop)**: Uses a VLM with lightweight geometric rules (~20 constraints) to select a skill from a pretrained library based on object shape and relative position.
- **ARGN (control loop)**: Recursively aggregates spatial memory over image patches with adaptive decay to mitigate vanishing gradients; fuses multi-scale visual features and refines predicted joint targets with a 6-component GMM for multi-modal action modes.
- **Data efficiency**: Demonstrates competency with sparse demonstrations (40 per skill) and maintains speed by avoiding iterative diffusion denoising.

## Alignment with ContinuonXR Architecture
- **HOPE / Nested Learning loops** (`docs/system-architecture.md`):
  - *Fast loop*: ARGN resembles the fast visuomotor adapter: deterministic feedforward inference over RGB+pose, amenable to on-device execution if quantized.
  - *Mid loop*: GSS acts as a mid-loop symbolic/semantic planner that dispatches reusable skills from a library, compatible with HOPE’s particle+wave routing if geometric rules are treated as wave-level priors.
  - *Slow loop*: Requires offline curation of geometric rules and GMM priors; aligns with slow-loop model updates and telemetry-driven refinement.
- **Multi-head VLA stack** (`docs/hope-cms-vla.md`):
  - The skill library and geometric adapters map cleanly to the “Skill head” and “Safety/Guard rails” components; bounding-box + mask inputs can flow through the Vision head, while language prompts remain unchanged.
  - The GMM-based action decoder can slot into the Action head as a compact alternative to diffusion policies, preserving compatibility with existing joint-space outputs.
- **Wavecore execution pipeline** (`docs/wavecore-spec.md`, `docs/wavecore-prd.md`):
  - GSS decisions can be represented as wave-level intents with shape-aware constraints, while ARGN produces particle-level control streams. Telemetry hooks should capture: bounding boxes, selected skill ID, decay factors, and mixture weights for observability and replay.

## Potential Integration Path (Theory)
1. **Prototype skill-selection plugin**: Replace or augment existing planner policies with GSS-style geometric heuristics over current VLM outputs; start with cylindrical vs. flat object rules using existing perception masks.
2. **ARGN-inspired action head**: Implement a lightweight recursive spatial mixer with RoPE and adaptive decay atop current vision encoders; use a small (e.g., K=6) GMM to model multi-modal joint targets for grasp/pinch/lift primitives.
3. **Data strategy**: Leverage small curated demonstration sets per primitive (≈40) to validate data-efficiency claims; compare against diffusion baselines already referenced in VLA specs.
4. **Safety and governance**: Gate geometric rules and GMM outputs through existing safety guards to prevent unsafe joint configurations; log mixture responsibilities and decay rates for anomaly detection.

## Considerations and Risks
- **Rule brittleness**: The 20-rule GSS set may not cover XR edge cases (transparent objects, deformables); needs human-in-the-loop review in the slow loop.
- **Perception dependency**: Requires reliable instance segmentation; consider fallback to bounding boxes with conservative skill choices when masks are low-confidence.
- **Control stability**: Recursive decay hyperparameters could impact stability; a capped decay floor and saturation checks should be added to the action head.
- **Deployment footprint**: GMM decoding is lightweight, but recursive mixing may still be heavier than current particle adapters; profiling on target devices is necessary.

## Next Steps
- Implement a sandboxed planner head with geometric priors and evaluate on existing XR grasp/pinch benchmarks.
- Build an ARGN-style head prototype using current vision backbone outputs and joint-space commands; compare success rates and latency with the diffusion-based baseline.
- Instrument telemetry to capture GSS decisions and ARGN mixture stats, then feed back into HOPE slow-loop tuning.
