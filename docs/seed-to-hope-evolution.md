# Seed Model: Universal Robot Initialization

**Version:** 1.2.0  
**Status:** Core Architecture  
**Date:** 2026-01-02

## Overview

The **Seed Model** is the universal initialization point for every robot in the Continuon ecosystem. It is not a temporary bootstrapâ€”it is a permanent, hardware-agnostic core that:

- **Initializes** every new robot that connects to the ecosystem
- **Runs on any chip**: ARM, x64, RISC-V, quantum, neuromorphic
- **Provides** the foundation for all higher-level capabilities
- **Evolves** through continuous learning while maintaining core stability

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEED MODEL: UNIVERSAL FOUNDATION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  New Robot Connects                                                          â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                         SEED MODEL                                      â”‚â”‚
â”‚  â”‚                   (Hardware-Agnostic Core)                              â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚â”‚
â”‚  â”‚  â”‚ ARM (Pi5)   â”‚  â”‚ x64 (PC)    â”‚  â”‚ RISC-V      â”‚  â”‚ Quantum     â”‚    â”‚â”‚
â”‚  â”‚  â”‚ Jetson      â”‚  â”‚ Server      â”‚  â”‚ Edge        â”‚  â”‚ Future      â”‚    â”‚â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚â”‚
â”‚  â”‚                                                                          â”‚â”‚
â”‚  â”‚  Universal Capabilities:                                                 â”‚â”‚
â”‚  â”‚  â€¢ World Model (next-token prediction)                                  â”‚â”‚
â”‚  â”‚  â€¢ Context Graph (relational reasoning)                                 â”‚â”‚
â”‚  â”‚  â€¢ Semantic Search (768-dim embeddings)                                 â”‚â”‚
â”‚  â”‚  â€¢ Decision Traces (explainability)                                     â”‚â”‚
â”‚  â”‚  â€¢ CMS Memory (multi-timescale)                                         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                    CONTINUOUS EVOLUTION                                  â”‚â”‚
â”‚  â”‚  Seed â†’ Experience â†’ Local Learning â†’ Cloud Aggregation â†’ OTA Update   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

The ContinuonBrain seed model demonstrates advanced embodied AI capabilities through a unified architecture that integrates:

- **World Models** for predictive next-token generation
- **Context Graphs** for relational reasoning
- **Semantic Search** via EmbeddingGemma-300m
- **Decision Traces** for explainable behavior
- **Multi-Timescale Memory** (CMS) for temporal abstraction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEED MODEL CAPABILITIES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ World Model  â”‚  â”‚ Context      â”‚  â”‚ Semantic     â”‚  â”‚ Decision     â”‚    â”‚
â”‚  â”‚ Prediction   â”‚  â”‚ Graph        â”‚  â”‚ Search       â”‚  â”‚ Traces       â”‚    â”‚
â”‚  â”‚              â”‚  â”‚ Reasoning    â”‚  â”‚              â”‚  â”‚              â”‚    â”‚
â”‚  â”‚ Next-token   â”‚  â”‚ Entity/      â”‚  â”‚ EmbeddingGemmaâ”‚  â”‚ Explainable  â”‚    â”‚
â”‚  â”‚ + action     â”‚  â”‚ Relation     â”‚  â”‚ 768-dim      â”‚  â”‚ Provenance   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                 â”‚                 â”‚                 â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                    WaveCore (Mamba SSM + Spectral)                     â”‚â”‚
â”‚  â”‚                    172K params | O(n) complexity                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                    CMS Memory (3-level hierarchical)                   â”‚â”‚
â”‚  â”‚                    Fast (100ms) | Mid (10s) | Slow (âˆ)                 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. World Model: Predictive Next-Token Generation

The seed model implements a **generative world model** that predicts future states, enabling:

- **Action-conditioned prediction**: Given current state `s_t` and action `a_t`, predict `s_{t+1}`
- **Multi-step rollouts**: Plan trajectories in latent space
- **Counterfactual reasoning**: "What if I had done X instead?"

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    WORLD MODEL PREDICTION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Observation (o_t)                                               â”‚
â”‚       â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Encoder: VQ-VAE / Vision Transformer                         â”‚â”‚
â”‚  â”‚ o_t â†’ z_t (discrete tokens or continuous embedding)          â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ WaveCore (Mamba SSM)                                         â”‚â”‚
â”‚  â”‚ h_t = SSM(h_{t-1}, z_t, a_{t-1})                             â”‚â”‚
â”‚  â”‚                                                               â”‚â”‚
â”‚  â”‚ State evolution: dh/dt = Ah + Bx                             â”‚â”‚
â”‚  â”‚ Selective gating: Î” = softplus(Linear(x))                    â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Next-Token Prediction Head                                    â”‚â”‚
â”‚  â”‚ p(z_{t+1} | h_t, a_t) = softmax(W_z Â· h_t)                   â”‚â”‚
â”‚  â”‚ p(r_t | h_t) = Reward prediction                              â”‚â”‚
â”‚  â”‚ p(done | h_t) = Episode termination                           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

```python
# continuonbrain/jax_models/core_model.py

class WorldModelHead(nn.Module):
    """Next-token prediction for world modeling."""
    config: CoreModelConfig
    
    @nn.compact
    def __call__(self, h_t: jnp.ndarray, a_t: jnp.ndarray) -> Dict[str, jnp.ndarray]:
        # Combine hidden state with action
        ha = jnp.concatenate([h_t, a_t], axis=-1)
        
        # Predict next latent
        z_next_logits = nn.Dense(self.config.num_vq_vocab)(ha)
        
        # Predict reward
        reward_pred = nn.Dense(1)(ha)
        
        # Predict done
        done_logits = nn.Dense(2)(ha)
        
        return {
            'z_next_logits': z_next_logits,
            'reward_pred': reward_pred,
            'done_logits': done_logits,
        }
```

### Training Objective

```python
# World model loss (next-token + reward + done)
L_world = L_reconstruction + Î»_r * L_reward + Î»_d * L_done

# Where:
# L_reconstruction = CrossEntropy(z_next_pred, z_next_true)
# L_reward = MSE(r_pred, r_true)
# L_done = CrossEntropy(done_pred, done_true)
```

---

## 2. Context Graph Reasoning

The seed model maintains a **context graph** for relational reasoning about entities, objects, and their relationships.

### Graph Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONTEXT GRAPH                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Nodes (Entities):                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚ Object  â”‚  â”‚ Person  â”‚  â”‚ Locationâ”‚  â”‚ Concept â”‚            â”‚
â”‚  â”‚ "cup"   â”‚  â”‚ "user"  â”‚  â”‚ "table" â”‚  â”‚ "hot"   â”‚            â”‚
â”‚  â”‚ emb[768]â”‚  â”‚ emb[768]â”‚  â”‚ emb[768]â”‚  â”‚ emb[768]â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â”‚
â”‚       â”‚            â”‚            â”‚            â”‚                  â”‚
â”‚  Edges (Relations):                                              â”‚
â”‚       â”‚            â”‚            â”‚            â”‚                  â”‚
â”‚       â””â”€â”€â”€â”€ on â”€â”€â”€â”€â”¼â”€â”€â”€â”€ near â”€â”€â”˜            â”‚                  â”‚
â”‚                    â”‚                         â”‚                  â”‚
â”‚                    â””â”€â”€â”€ wants â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                  â”‚
â”‚  Edge Attributes:                                                â”‚
â”‚  - type: spatial | causal | semantic | temporal                  â”‚
â”‚  - weight: attention-based salience                              â”‚
â”‚  - provenance: which observation created this edge               â”‚
â”‚  - timestamp: when last updated                                  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Graph Operations

```python
# continuonbrain/core/context_graph_store.py

class ContextGraphStore:
    """Graph-based reasoning for embodied agents."""
    
    def add_observation(self, obs: Observation) -> None:
        """Update graph from visual/sensor observation."""
        # Extract entities
        entities = self.vision_core.detect_objects(obs.image)
        
        # Add/update nodes
        for entity in entities:
            node = GraphNode(
                id=entity.track_id,
                type=entity.category,
                embedding=self.embed(entity.label),
                attributes={
                    'bbox': entity.bbox,
                    'confidence': entity.score,
                    'depth': entity.depth,
                },
                timestamp=obs.timestamp,
            )
            self.graph.upsert_node(node)
        
        # Infer spatial relations
        for e1, e2 in itertools.combinations(entities, 2):
            relation = self.infer_spatial_relation(e1, e2)
            if relation:
                self.graph.add_edge(e1.id, e2.id, relation)
    
    def query(self, question: str) -> List[GraphNode]:
        """Semantic graph traversal for question answering."""
        query_emb = self.embed(question)
        
        # Find relevant nodes
        candidates = self.graph.semantic_search(query_emb, k=10)
        
        # Expand via relations
        expanded = self.graph.expand_neighbors(candidates, hops=2)
        
        return self.rank_by_relevance(expanded, query_emb)
    
    def reason(self, goal: str) -> ReasoningTrace:
        """Multi-hop reasoning over graph."""
        trace = ReasoningTrace()
        
        # Parse goal into subgoals
        subgoals = self.parse_goal(goal)
        
        for subgoal in subgoals:
            # Find relevant context
            context = self.query(subgoal)
            
            # Apply reasoning rules
            conclusions = self.apply_rules(context, subgoal)
            
            trace.add_step(subgoal, context, conclusions)
        
        return trace
```

### Graph Attention for Reasoning

```python
# Multi-head graph attention for relation reasoning
class GraphAttention(nn.Module):
    """Graph attention for context reasoning."""
    
    @nn.compact
    def __call__(self, nodes: jnp.ndarray, edges: jnp.ndarray, query: jnp.ndarray):
        # nodes: [N, d], edges: [E, 2], query: [d]
        
        # Compute attention scores
        Q = nn.Dense(64)(query)
        K = nn.Dense(64)(nodes)
        V = nn.Dense(64)(nodes)
        
        # Edge-aware attention
        attn = jnp.einsum('d,nd->n', Q, K) / jnp.sqrt(64)
        attn = nn.softmax(attn)
        
        # Aggregate
        context = jnp.einsum('n,nd->d', attn, V)
        
        return context, attn
```

---

## 3. Semantic Search

The seed model uses **EmbeddingGemma-300m** for 768-dimensional semantic embeddings, enabling:

- **Experience retrieval**: Find similar past interactions
- **Knowledge grounding**: Connect observations to learned concepts
- **Cross-modal search**: Match text queries to visual memories

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEMANTIC SEARCH PIPELINE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Query: "Where did I put my keys?"                               â”‚
â”‚       â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ EmbeddingGemma-300m                                          â”‚â”‚
â”‚  â”‚ "Where did I put my keys?" â†’ q âˆˆ â„^768                       â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â†“                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Vector Index (FAISS / ScaNN)                                  â”‚â”‚
â”‚  â”‚ top_k = argmax_i cos(q, e_i)                                 â”‚â”‚
â”‚  â”‚                                                               â”‚â”‚
â”‚  â”‚ Indexed memories:                                             â”‚â”‚
â”‚  â”‚ - RLDS episodes (91K steps)                                   â”‚â”‚
â”‚  â”‚ - Conversation history                                        â”‚â”‚
â”‚  â”‚ - Visual observations                                         â”‚â”‚
â”‚  â”‚ - Context graph nodes                                         â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â†“                                                          â”‚
â”‚  Retrieved: [                                                    â”‚
â”‚    "You placed keys on the kitchen counter (0.89)",              â”‚
â”‚    "Keys were last seen near the door (0.76)",                   â”‚
â”‚    "Conversation about losing keys yesterday (0.71)",            â”‚
â”‚  ]                                                               â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

```python
# continuonbrain/services/embedding_gemma.py

class EmbeddingGemmaEncoder:
    """768-dim semantic embeddings for search and retrieval."""
    
    DEFAULT_MODEL_ID = "google/embeddinggemma-300m"
    
    def encode_query(self, query: str) -> np.ndarray:
        """Encode search query with query-specific prompt."""
        prompt = f"search_query: {query}"
        return self.model.encode([prompt])[0]
    
    def encode_document(self, doc: str) -> np.ndarray:
        """Encode document/memory for indexing."""
        prompt = f"search_document: {doc}"
        return self.model.encode([prompt])[0]
    
    def encode_batch(self, texts: List[str], is_query: bool = False) -> np.ndarray:
        """Batch encode for efficiency."""
        prefix = "search_query: " if is_query else "search_document: "
        prompts = [prefix + t for t in texts]
        return self.model.encode(prompts)

# Usage in experience logger
class ExperienceLogger:
    def search_conversations(self, query: str, max_results: int = 5) -> List[Dict]:
        query_embedding = self.encoder.encode_query(query)
        
        # Search vector index
        distances, indices = self.index.search(
            query_embedding.reshape(1, -1), 
            max_results
        )
        
        # Return ranked results with relevance scores
        return [
            {
                **self.memories[idx],
                'relevance': 1 - distances[0][i],  # Convert distance to similarity
            }
            for i, idx in enumerate(indices[0])
        ]
```

---

## 4. Decision Traces

The seed model logs **decision traces** for explainable AI, enabling:

- **Provenance tracking**: Why did the agent take this action?
- **Debugging**: Trace failures back to root causes
- **Learning from mistakes**: Identify and correct decision patterns

### Trace Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DECISION TRACE                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  trace_id: "dt_20260102_100523_abc123"                          â”‚
â”‚  timestamp: 2026-01-02T10:05:23.456Z                            â”‚
â”‚  agent: "hope_agent_manager"                                     â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Input Context                                              â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ observation: { image: "...", depth: "...", pose: [...] }   â”‚  â”‚
â”‚  â”‚ user_query: "Pick up the red cup"                          â”‚  â”‚
â”‚  â”‚ memory_context: [                                          â”‚  â”‚
â”‚  â”‚   { text: "Red cup is on table", salience: 0.92 },         â”‚  â”‚
â”‚  â”‚   { text: "User prefers left hand", salience: 0.71 },      â”‚  â”‚
â”‚  â”‚ ]                                                          â”‚  â”‚
â”‚  â”‚ graph_context: [                                           â”‚  â”‚
â”‚  â”‚   { node: "red_cup", relation: "on", target: "table" },    â”‚  â”‚
â”‚  â”‚ ]                                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Reasoning Steps                                            â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ 1. Goal parsing: "pick up" â†’ GRASP action                  â”‚  â”‚
â”‚  â”‚ 2. Object grounding: "red cup" â†’ object_id: "cup_42"       â”‚  â”‚
â”‚  â”‚ 3. Spatial reasoning: cup at (0.3, 0.5, 0.1) in base_link  â”‚  â”‚
â”‚  â”‚ 4. Path planning: 5-waypoint trajectory generated          â”‚  â”‚
â”‚  â”‚ 5. Safety check: PASSED (no obstacles, reachable)          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Decision                                                   â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ action: "grasp"                                            â”‚  â”‚
â”‚  â”‚ target: "cup_42"                                           â”‚  â”‚
â”‚  â”‚ confidence: 0.94                                           â”‚  â”‚
â”‚  â”‚ alternatives: [                                            â”‚  â”‚
â”‚  â”‚   { action: "ask_clarify", confidence: 0.03 },             â”‚  â”‚
â”‚  â”‚   { action: "point_to", confidence: 0.02 },                â”‚  â”‚
â”‚  â”‚ ]                                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Outcome                                                    â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ success: true                                              â”‚  â”‚
â”‚  â”‚ reward: 1.0                                                â”‚  â”‚
â”‚  â”‚ feedback: null                                             â”‚  â”‚
â”‚  â”‚ error: null                                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation

```python
# continuonbrain/core/decision_trace_logger.py

@dataclass
class DecisionTrace:
    trace_id: str
    timestamp: datetime
    agent: str
    input_context: InputContext
    reasoning_steps: List[ReasoningStep]
    decision: Decision
    outcome: Optional[Outcome] = None

class DecisionTraceLogger:
    """Log decision traces for explainability and learning."""
    
    def start_trace(self, agent: str, observation: Observation) -> DecisionTrace:
        return DecisionTrace(
            trace_id=f"dt_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid4().hex[:6]}",
            timestamp=datetime.now(),
            agent=agent,
            input_context=InputContext(observation=observation),
            reasoning_steps=[],
            decision=None,
        )
    
    def add_reasoning_step(self, trace: DecisionTrace, step: ReasoningStep) -> None:
        trace.reasoning_steps.append(step)
    
    def set_decision(self, trace: DecisionTrace, decision: Decision) -> None:
        trace.decision = decision
    
    def record_outcome(self, trace: DecisionTrace, outcome: Outcome) -> None:
        trace.outcome = outcome
        
        # Log to RLDS for learning
        self.log_to_rlds(trace)
        
        # Update context graph
        self.context_graph.add_decision_edge(trace)
    
    def log_to_rlds(self, trace: DecisionTrace) -> None:
        """Convert trace to RLDS episode step."""
        step = {
            'observation': trace.input_context.to_dict(),
            'action': trace.decision.action,
            'reward': trace.outcome.reward if trace.outcome else 0.0,
            'metadata': {
                'trace_id': trace.trace_id,
                'reasoning_steps': [s.to_dict() for s in trace.reasoning_steps],
                'confidence': trace.decision.confidence,
            }
        }
        self.rlds_logger.log_step(step)
```

---

## 5. Multi-Timescale Memory (CMS)

The **Continuous Memory System** provides hierarchical temporal abstraction:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CMS HIERARCHY                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  Level 0: FAST (Episodic)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Ï„ = 100ms | decay = 0.9 | slots = 64                        â”‚â”‚
â”‚  â”‚ Content: Raw sensory, motor commands, immediate context     â”‚â”‚
â”‚  â”‚ Update: Every perception cycle                               â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                         â”‚                                        â”‚
â”‚                         â–¼ consolidation                          â”‚
â”‚  Level 1: MID (Working)                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Ï„ = 10s | decay = 0.99 | slots = 128                        â”‚â”‚
â”‚  â”‚ Content: Current task state, active goals, recent events    â”‚â”‚
â”‚  â”‚ Update: Event-driven (significant changes)                   â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                         â”‚                                        â”‚
â”‚                         â–¼ consolidation                          â”‚
â”‚  Level 2: SLOW (Semantic)                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Ï„ = âˆ | decay = 0.999 | slots = 256                         â”‚â”‚
â”‚  â”‚ Content: Learned skills, persistent knowledge, identity     â”‚â”‚
â”‚  â”‚ Update: Sleep-like consolidation (background)                â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                                                  â”‚
â”‚  Memory Operations:                                              â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚  READ:  c_t = CMS_Read(M, query)                                â”‚
â”‚         Attention-weighted retrieval across all levels           â”‚
â”‚                                                                  â”‚
â”‚  WRITE: M_t = (1-Î±)M_{t-1} + Î±Â·new_memory                       â”‚
â”‚         Content-addressable write with salience gating           â”‚
â”‚                                                                  â”‚
â”‚  CONSOLIDATE: M_slow = consolidate(M_fast, M_mid)               â”‚
â”‚         Pattern compression, schema extraction                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation (JAX)

```python
# continuonbrain/jax_models/cms_jax.py

class CMSMemory(nn.Module):
    """JAX implementation of Continuous Memory System."""
    config: CMSConfig
    
    @nn.compact
    def __call__(
        self,
        query: jnp.ndarray,       # [B, d_query]
        memories: List[jnp.ndarray],  # [[B, N_l, d_l], ...]
        keys: List[jnp.ndarray],      # [[B, N_l, d_k], ...]
    ) -> Tuple[jnp.ndarray, List[jnp.ndarray]]:
        """Read from hierarchical memory."""
        
        contexts = []
        attentions = []
        
        for level, (M, K) in enumerate(zip(memories, keys)):
            # Compute attention
            # scores[b, n] = query[b] Â· K[b, n] / âˆšd_k
            scores = jnp.einsum('bd,bnd->bn', query, K) / jnp.sqrt(self.config.d_k)
            attn = nn.softmax(scores, axis=-1)
            
            # Retrieve context
            # c[b, d] = Î£_n attn[b, n] * M[b, n, d]
            c = jnp.einsum('bn,bnd->bd', attn, M)
            
            contexts.append(c)
            attentions.append(attn)
        
        # Hierarchical mixing
        # Learn to weight different timescales
        stacked = jnp.stack(contexts, axis=1)  # [B, L, d]
        mix_weights = nn.softmax(
            nn.Dense(self.config.num_levels)(query), axis=-1
        )  # [B, L]
        
        mixed = jnp.einsum('bl,bld->bd', mix_weights, stacked)
        
        return mixed, attentions
    
    def write(
        self,
        memories: List[jnp.ndarray],
        keys: List[jnp.ndarray],
        new_content: jnp.ndarray,
        new_key: jnp.ndarray,
        salience: float,
    ) -> Tuple[List[jnp.ndarray], List[jnp.ndarray]]:
        """Write to memory with decay and salience gating."""
        
        updated_memories = []
        updated_keys = []
        
        for level, (M, K) in enumerate(zip(memories, keys)):
            decay = self.config.decays[level]
            
            # Find least salient slot
            saliences = jnp.linalg.norm(M, axis=-1)  # [B, N]
            min_idx = jnp.argmin(saliences, axis=-1)  # [B]
            
            # Decay existing memories
            M_decayed = M * decay
            K_decayed = K * decay
            
            # Write new content if salient enough
            if salience > self.config.write_threshold:
                # Replace least salient slot
                M_new = M_decayed.at[:, min_idx].set(new_content)
                K_new = K_decayed.at[:, min_idx].set(new_key)
            else:
                M_new = M_decayed
                K_new = K_decayed
            
            updated_memories.append(M_new)
            updated_keys.append(K_new)
        
        return updated_memories, updated_keys
```

---

## 6. Advanced Embodied AI Concepts

### 6.1 Action-Perception Loop

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    EMBODIED ACTION-PERCEPTION LOOP               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Sensors â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ Encoder â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â”‚
â”‚      â–²                                               â”‚          â”‚
â”‚      â”‚                                               â–¼          â”‚
â”‚      â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚      â”‚                                    â”‚ World Model      â”‚  â”‚
â”‚      â”‚                                    â”‚ State: h_t       â”‚  â”‚
â”‚      â”‚                                    â”‚ Predict: áº‘_{t+1} â”‚  â”‚
â”‚      â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â”‚                                             â”‚            â”‚
â”‚      â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚      â”‚         â”‚                                                â”‚
â”‚      â”‚         â–¼                                                â”‚
â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚      â”‚  â”‚ CMS Memory â”‚â—„â”€â”€â”€â–ºâ”‚ HOPE Core   â”‚â—„â”€â”€â”€â–ºâ”‚ Context    â”‚  â”‚
â”‚      â”‚  â”‚ Retrieval  â”‚     â”‚ Reasoning   â”‚     â”‚ Graph      â”‚  â”‚
â”‚      â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚      â”‚                            â”‚                             â”‚
â”‚      â”‚                            â–¼                             â”‚
â”‚      â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚      â”‚                     â”‚ Policy     â”‚                       â”‚
â”‚      â”‚                     â”‚ Ï€(a|s,g)   â”‚                       â”‚
â”‚      â”‚                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚      â”‚                           â”‚                              â”‚
â”‚      â”‚                           â–¼                              â”‚
â”‚  â”Œâ”€â”€â”€â”´â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚ Robot â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ Actuators  â”‚                        â”‚
â”‚  â”‚ Body  â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Intrinsic Motivation

```python
# Curiosity-driven exploration
class IntrinsicMotivation:
    """Compute intrinsic rewards for exploration."""
    
    def compute_curiosity(self, state: jnp.ndarray, next_state: jnp.ndarray) -> float:
        """Prediction error as curiosity signal."""
        predicted = self.forward_model(state)
        error = jnp.mean((predicted - next_state) ** 2)
        return float(error)
    
    def compute_empowerment(self, state: jnp.ndarray) -> float:
        """Mutual information between actions and outcomes."""
        # I(a; s' | s) - how much control does the agent have?
        return self.empowerment_estimator(state)
    
    def compute_novelty(self, state: jnp.ndarray) -> float:
        """Distance from visited states."""
        distances = self.memory.query_nearest(state, k=5)
        return float(jnp.mean(distances))
```

### 6.3 Skill Learning

```python
# Hierarchical skill learning
class SkillLibrary:
    """Learned reusable behaviors."""
    
    skills: Dict[str, Skill] = {
        'grasp': Skill(
            preconditions=['object_visible', 'arm_reachable'],
            policy=GraspPolicy(),
            postconditions=['object_held'],
        ),
        'place': Skill(
            preconditions=['object_held', 'target_visible'],
            policy=PlacePolicy(),
            postconditions=['object_placed'],
        ),
        'navigate': Skill(
            preconditions=['target_known'],
            policy=NavigatePolicy(),
            postconditions=['at_target'],
        ),
    }
    
    def select_skill(self, goal: str, context: Dict) -> Optional[Skill]:
        """Select appropriate skill for goal."""
        for name, skill in self.skills.items():
            if skill.matches_goal(goal) and skill.check_preconditions(context):
                return skill
        return None
```

---

## 7. Hardware-Agnostic Architecture

The seed model is designed to run on **any compute platform**â€”from edge devices to quantum processors.

### Supported Architectures

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HARDWARE PORTABILITY MATRIX                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  Architecture      â”‚ Runtime        â”‚ Accelerator      â”‚ Status            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  ARM64 (Pi5)       â”‚ JAX CPU        â”‚ Hailo-8 NPU      â”‚ âœ… Primary        â”‚
â”‚  ARM64 (Jetson)    â”‚ JAX CUDA       â”‚ Tensor Cores     â”‚ âœ… Supported      â”‚
â”‚  x86_64 (PC)       â”‚ JAX CPU/CUDA   â”‚ NVIDIA GPU       â”‚ âœ… Supported      â”‚
â”‚  x86_64 (Cloud)    â”‚ JAX TPU        â”‚ TPU v4/v5        â”‚ âœ… Supported      â”‚
â”‚  RISC-V            â”‚ Portable C     â”‚ Custom NPU       â”‚ ğŸ”¶ Planned        â”‚
â”‚  Apple Silicon     â”‚ JAX Metal      â”‚ ANE              â”‚ ğŸ”¶ Planned        â”‚
â”‚  Quantum           â”‚ Pennylane/JAX  â”‚ QPU              â”‚ ğŸ”® Future         â”‚
â”‚  Neuromorphic      â”‚ Lava/Loihi     â”‚ Intel Loihi 2    â”‚ ğŸ”® Future         â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Portability Principles

1. **Pure JAX Core**: All core computations use JAX, which compiles to XLA for any backend
2. **No Hardware-Specific Code in Model**: Hardware abstraction at the inference router level
3. **Graceful Degradation**: Falls back to CPU when accelerators unavailable
4. **Quantization-Ready**: Weights can be quantized for edge deployment

### Backend Selection

```python
# Automatic backend selection based on available hardware
from continuonbrain.jax_models.export.inference_router import InferenceRouter

router = InferenceRouter()

# Automatically selects best available backend:
# 1. TPU (if on Cloud TPU VM)
# 2. CUDA (if NVIDIA GPU available)
# 3. Hailo (if Hailo-8 NPU detected)
# 4. CPU (always available fallback)

output = router.infer(observation)
print(f"Backend used: {router.active_backend}")  # e.g., "hailo", "cuda", "cpu"
```

### Edge Deployment

```python
# Optimized for edge devices (Pi5, Jetson, etc.)
from continuonbrain.jax_models.config import CoreModelConfig

# Automatic config based on detected hardware
config = CoreModelConfig.for_device()  # Detects and optimizes

# Manual override for specific hardware
config_pi5 = CoreModelConfig.pi5_optimized()      # 172K params, fits in 512MB
config_jetson = CoreModelConfig.jetson_optimized() # Larger model for Jetson
config_cloud = CoreModelConfig.cloud_optimized()   # Full model for TPU
```

### Seed Model Initialization Flow

Every new robot, regardless of hardware, starts with the same seed:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NEW ROBOT INITIALIZATION                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                              â”‚
â”‚  1. Robot boots for first time                                               â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚  2. Hardware detection (RuntimeContext)                                      â”‚
â”‚       â”‚  Detects: CPU arch, RAM, GPU/NPU, sensors                           â”‚
â”‚       â–¼                                                                      â”‚
â”‚  3. Download/verify seed model                                               â”‚
â”‚       â”‚  From: continuon.cloud/seed/v1.0.0/                                 â”‚
â”‚       â”‚  Checksum: verified against manifest                                â”‚
â”‚       â–¼                                                                      â”‚
â”‚  4. Select optimal config for hardware                                       â”‚
â”‚       â”‚  Pi5 â†’ pi5_optimized (172K params)                                  â”‚
â”‚       â”‚  Jetson â†’ jetson_optimized (1M params)                              â”‚
â”‚       â”‚  Cloud â†’ cloud_optimized (10M params)                               â”‚
â”‚       â–¼                                                                      â”‚
â”‚  5. Initialize WaveCore + CMS + Context Graph                               â”‚
â”‚       â”‚  All capabilities ready                                              â”‚
â”‚       â–¼                                                                      â”‚
â”‚  6. Robot operational with full seed capabilities                           â”‚
â”‚       â”‚                                                                      â”‚
â”‚       â–¼                                                                      â”‚
â”‚  7. Begin experience collection â†’ local learning â†’ evolution                â”‚
â”‚                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cross-Platform Serialization

```python
# Seed model weights are platform-agnostic
import numpy as np

# Save (any platform)
weights = {'params': jax.tree_util.tree_map(np.array, params)}
np.savez('seed_model.npz', **weights)

# Load (any platform)
loaded = np.load('seed_model.npz', allow_pickle=True)
params = jax.tree_util.tree_map(jnp.array, dict(loaded))
```

---

## 8. Training Pipeline

### Continuous Learning (Post-Initialization)

After seed initialization, robots learn continuously:

| Phase | Location | Data | Frequency |
|-------|----------|------|-----------|
| **Experience Collection** | Device | RLDS episodes | Continuous |
| **Local Learning** | Device | Fast/Mid loops | Every session |
| **Cloud Aggregation** | TPU | Aggregated RLDS | Daily/Weekly |
| **OTA Distribution** | Cloud â†’ Device | Updated weights | On-demand |

### Seed Model (Core - Never Deprecated)

| Component | Status | Details |
|-----------|--------|---------|
| **WaveCore** | âœ… 172K params | Mamba SSM, O(n) complexity |
| **CMS** | âœ… 3 levels | Fast/Mid/Slow with decay |
| **Scaffold** | ğŸ”¶ Gemma 3n | Chat generation (evolves with updates) |
| **Embeddings** | âœ… 768-dim | EmbeddingGemma (permanent) |
| **RLDS** | âœ… 4,219 episodes | 91K steps available |

### Production Phase (Post-Seed)

```
Device RLDS â”€â”€â–º Cloud TPU Slow Loop â”€â”€â–º OTA Bundle â”€â”€â–º Device Install
                     â”‚
                     â–¼
              WaveCore Production Weights
              (Gemma scaffold deprecated)
```

---

## 8. References

- [WaveCore Spec](./wavecore-spec.md)
- [HOPE/CMS VLA](./hope-cms-vla.md)
- [CMS Formal Spec](../continuonbrain/docs/CMS_FORMAL_SPEC.md)
- [RCAN Protocol](./rcan-protocol.md)
- [Training Plan](./training-plan.md)
