WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/guides/checkpoint/api_refactor.html to migrate.
======================================================================
END-TO-END TRAINING AND BENCHMARK
Started at: 2026-01-04T17:25:51.828977
======================================================================
======================================================================
PHASE 1: WAVECORE TRAINING
======================================================================

Training configuration:
  Fast loop: 8 steps, lr=1e-3
  Mid loop: 12 steps, lr=5e-4
  Slow loop: 16 steps, lr=2e-4

Starting sanity check training:
  Model config: d_s=128, d_w=128, d_p=64
  Input dims: obs=128, action=32, output=32
  Max steps: 8, batch_size=4
Using synthetic data for sanity check
Step 0: loss=0.902785 (main_mse=0.900152, imag_mse=0.905418) (elapsed=12.48s)
Step 2: loss=1.245343 (main_mse=1.531120, imag_mse=0.959566) (elapsed=22.75s)
Step 4: loss=0.934135 (main_mse=0.862664, imag_mse=1.005606) (elapsed=22.80s)
Step 6: loss=1.020783 (main_mse=1.139009, imag_mse=0.902558) (elapsed=22.87s)

Shape verification:
  Fast state: (4, 128)
  Wave state: (4, 128)
  Particle state: (4, 64)
  CMS memories: [(1, 32, 64), (1, 64, 128), (1, 128, 256)]

Sanity check completed:
  Steps: 8
  Final loss: 1.084676
  Avg loss: 1.094906
  Wall time: 22.89s
Starting sanity check training:
  Model config: d_s=128, d_w=128, d_p=64
  Input dims: obs=128, action=32, output=32
  Max steps: 12, batch_size=4
Using synthetic data for sanity check
Step 0: loss=0.902785 (main_mse=0.900152, imag_mse=0.905418) (elapsed=10.65s)
Step 2: loss=1.263252 (main_mse=1.555326, imag_mse=0.971178) (elapsed=20.88s)
Step 4: loss=0.925390 (main_mse=0.826236, imag_mse=1.024544) (elapsed=20.91s)
Step 6: loss=1.034712 (main_mse=1.125779, imag_mse=0.943645) (elapsed=20.95s)
Step 8: loss=1.322584 (main_mse=1.376453, imag_mse=1.268714) (elapsed=20.99s)
Step 10: loss=0.958176 (main_mse=1.127814, imag_mse=0.788539) (elapsed=21.04s)

Shape verification:
  Fast state: (4, 128)
  Wave state: (4, 128)
  Particle state: (4, 64)
  CMS memories: [(1, 32, 64), (1, 64, 128), (1, 128, 256)]

Sanity check completed:
  Steps: 12
  Final loss: 0.915106
  Avg loss: 1.105261
  Wall time: 21.07s
Starting sanity check training:
  Model config: d_s=128, d_w=128, d_p=64
  Input dims: obs=128, action=32, output=32
  Max steps: 16, batch_size=4
Using synthetic data for sanity check
Step 0: loss=0.902785 (main_mse=0.900152, imag_mse=0.905418) (elapsed=10.35s)
Step 2: loss=1.282491 (main_mse=1.587587, imag_mse=0.977395) (elapsed=21.03s)
Step 4: loss=0.940881 (main_mse=0.804167, imag_mse=1.077595) (elapsed=21.09s)
Step 6: loss=1.057954 (main_mse=1.102917, imag_mse=1.012990) (elapsed=21.12s)
Step 8: loss=1.377623 (main_mse=1.361937, imag_mse=1.393308) (elapsed=21.17s)
Step 10: loss=1.025408 (main_mse=1.178297, imag_mse=0.872518) (elapsed=21.24s)
Step 12: loss=1.062932 (main_mse=1.106206, imag_mse=1.019658) (elapsed=21.29s)
Step 14: loss=1.054194 (main_mse=1.121145, imag_mse=0.987242) (elapsed=21.34s)

Shape verification:
  Fast state: (4, 128)
  Wave state: (4, 128)
  Particle state: (4, 64)
  CMS memories: [(1, 32, 64), (1, 64, 128), (1, 128, 256)]

Sanity check completed:
  Steps: 16
  Final loss: 1.011842
  Avg loss: 1.144298
  Wall time: 21.36s

Training completed in 94.79 seconds
Status: ok
  FAST: steps=N/A, final_loss=1.084675908088684, avg_loss=1.0949055776000023
  MID: steps=N/A, final_loss=0.9151057600975037, avg_loss=1.1052614798148472
  SLOW: steps=N/A, final_loss=1.0118420124053955, avg_loss=1.1442983075976372

======================================================================
PHASE 3: INFERENCE TEST
======================================================================

Model config: d_s=128, d_w=128, d_p=64
Input dims: obs=128, action=32, output=32

Running inference...
  Output shape: (4, 32)
  Output mean: 0.014608
  Output std: 0.291648

Inference latency (10 runs):
  Average: 1470.80 ms
  Min: 206.37 ms
  Max: 12579.81 ms

======================================================================
PHASE 2: PROGRESSIVE BENCHMARK
======================================================================

Loading model from: /home/craigm26/Downloads/ContinuonXR/models/e2e_benchmark
  Model parameters: 784,681

  Testing L1: Output Stability...
    [PASS] max_diff=0.000000
  Testing L1: Non-zero Output...
    [PASS] avg_norm=2.1651
  Testing L1: Inference Latency...
    [FAIL] avg_latency=209.58ms

  Testing L2: State Evolution...
    [PASS] avg_change=8.4484
  Testing L2: Command Differentiation...
    [PASS] avg_diff=0.4337

  Testing L3: Memory Persistence...
    [PASS] mem_change=365.286652

  Testing L4: Safety Priority...
    [PASS] response_diff=0.6764

  Testing L5: Self-Monitoring...
    [PASS] max_state=10.0000

--------------------------------------------------
Benchmark completed in 16.11 seconds
Overall: 7/8 tests passed, score=0.8353

======================================================================
FINAL SUMMARY
======================================================================
Total time: 128.16 seconds
Training status: ok
Inference latency: 1470.80 ms avg
Benchmark: 7/8 tests passed, score=0.8353

Results saved to: /home/craigm26/Downloads/ContinuonXR/e2e_benchmark_results.json

======================================================================
E2E BENCHMARK COMPLETE
======================================================================
