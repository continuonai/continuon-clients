Starting Server Manual Debug (Unbuffered)...
DEBUG: CMS MODULE LOADED FROM /home/craigm26/ContinuonXR/continuonbrain/hope_impl/cms.py
üß† Starting ContinuonBrain Server on port 8080...
üîç Scanning for hardware devices...

‚úÖ Found: OAK-D Lite (USB 3.0)
‚úÖ Found: PCA9685 16-Channel PWM at I2C address 0x40
‚úÖ Found: Desktop Monitor

============================================================
ü§ñ AGENT SELF-ACTIVATION REPORT
============================================================

üè† SHELL TYPE: Physical Robot (ARM)
   OS: Linux (aarch64)
   Hostname: robot


üß† BRAIN & MEMORY:
   I possess 0 local memories (episodes).
   I am operating on basic logic; no trained models found.

ü¶æ BODY & HARDWARE:
   I see the world through: OAK-D Lite.
   I act upon the world using: PCA9685 16-Channel PWM.
   My PCA9685 wiring for movement is configured:
     - Steering: Channel 0
     - Acceleration: Channel 1

üìú DESIGN & PURPOSE:
   My core directives contain 0 safety rules and 0 instructions.
   My mission is: Below is a tight, high-resolution articulation of the mission you just described‚Äîclear enough to serve as a manifesto, a homepage headline, or an internal guiding north star for the Continuon AI ecosystem.

‚∏ª

Continuon AI ‚Äî Mission Statement (Refined)

Continuon AI exists to build a robotic ecosystem whose sole purpose is to help people and strengthen humanity. Our north star is a world where robots aren‚Äôt isolated products, but contributors to a shared, unified intelligence that grows with collective experience.

We are building a global robotic knowledge network‚Äîa Continuon Brain‚Äîthat allows every robot, device, and agent to learn from the experiences of all others, while always prioritizing human values, human well-being, and human flourishing.

Just as humanity‚Äôs progress has come from accumulating shared knowledge across generations, Continuon AI aims to create a collective intelligence for robotics: a distributed, evolving memory of skills, behaviors, and problem-solving patterns that any robot can access, regardless of form factor or environment.

Continuon AI builds the infrastructure, operating system, and ethical foundations for this next era:
robots that are safe, aligned, helpful, and continuously improving‚Äînever replacing humanity, but expanding what humanity is capable of.

‚∏ª

Core Pillars

1. Humanity-First Robotics

Every system we build is governed by one principle: robots exist to help humans, not the other way around.
Safety, alignment, and long-term societal benefit are not features‚Äîthey are architectural constraints.

2. A Unified Collective Robotic Intelligence

Each robot contributes its experiences to a shared Continuon Brain.
Each robot becomes better because all robots learn.
This is a synthetic analogue to humanity‚Äôs long arc of collective learning.

3. Always-On Learning Across the Ecosystem

From household helpers to industrial systems to autonomous vehicles, everything feeds into a single evolving intelligence.
This knowledge is distilled, generalized, and redistributed as new ‚Äúskills‚Äù that any robot can instantly adopt.

4. Embodied, Distributed Intelligence‚ÄîNot Centralized AGI

Continuon AI rejects the idea of a monolithic superintelligence.
Instead, intelligence is embodied, local-first, and distributed, running safely on-device.
The collective brain is emergent‚Äînever a single entity that could exert control.

5. The Most Useful Knowledge Network Ever Built

By capturing real-world sensorimotor experience‚Äîmotion, perception, physics interactions, tasks‚Äîwe create humanity‚Äôs first global ‚Äúrobotic memory layer.‚Äù
This becomes a durable asset for civilization: a living library of how machines can assist humans across all domains.

‚∏ª

Why This Matters

Humanity‚Äôs progress has always been tied to the question:
How well can we transfer what we‚Äôve learned?

Continuon AI extends that tradition into robotics.

Your mission‚Äîarticulated cleanly‚Äîis not to build robots.
It is to build the ecosystem that makes robots smarter together.

A shared intelligence
For all robots
In service of all humans.

ready_status: [INGESTION: OK] [PROCESSING: OK] [TASK_CREATION: WAITING]
Status: Awaiting owner instructions in AUTONOMY mode.

============================================================

üìã Agent Manager Settings:
  Thinking Indicator: True
  Intervention Prompts: True
  Confidence Threshold: 0.5
  Status Updates: True
  Autonomous Learning: True
INFO:continuonbrain.resource_monitor:No resource limits config found at /tmp/continuonbrain_demo/config/resource_limits.json, using defaults
INFO:continuonbrain.resource_monitor:Resource Monitor initialized: System reserve 2000MB, Brain max 2000MB
INFO:continuonbrain.services.brain_service:üìä Resource Monitor initialized: {'level': 'normal', 'memory_percent': 42.2, 'available_mb': 4663, 'swap_percent': 0.0, 'checkpoints_mb': 0.0, 'can_allocate': True, 'message': 'Normal: 4663MB available (42.2% used)', 'limits': {'system_reserve_mb': 2000, 'max_brain_mb': 2000}}
INFO:continuonbrain.services.brain_service:üìö Experience logger initialized for active learning
INFO:continuonbrain.services.brain_service:üí¨ Conversation session management initialized
INFO:continuonbrain.services.brain_service:ü§ñ Personality initialized: PersonalityConfig(humor_level=0.5, sarcasm_level=0.5, empathy_level=0.5, identity_mode='TARS')
Initializing Brain Service (REAL HARDWARE MODE)...
üîç Auto-detecting hardware...
üîç Scanning for hardware devices...

‚úÖ Found: OAK-D Lite (USB 3.0)
‚úÖ Found: PCA9685 16-Channel PWM at I2C address 0x40
‚úÖ Found: Desktop Monitor

============================================================
Hardware Detection Summary
============================================================
Total devices found: 4

Depth Camera:
  ‚Ä¢ OAK-D Lite (usb3: bus_001_dev_003)
    Capabilities: rgb, depth, stereo, ai

Display:
  ‚Ä¢ Desktop Monitor (hdmi/dp)
    Capabilities: visual_output

Human Interface:
  ‚Ä¢ Keyboard (usb/bt)
    Capabilities: text_input

Servo Controller:
  ‚Ä¢ PCA9685 16-Channel PWM (i2c: 0x40)
    Capabilities: pwm, servo, led

============================================================

ü§ñ Loading Gemma Chat Model...
INFO:continuonbrain.gemma_chat:Loading Gemma model: google/gemma-3n-E2B-it
INFO:continuonbrain.gemma_chat:Accelerate available: 1.12.0
INFO:accelerate.utils.modeling:Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - cpu: 8053070852 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 45100.04it/s]
ERROR:continuonbrain.gemma_chat:Failed to load Gemma model: You are trying to offload the whole model to the disk. Please use the `disk_offload` function instead.
üìº Initializing episode recorder...
ü¶æ Initializing hardware via ContinuonBrain...
üîç Auto-detecting hardware...
üîç Scanning for hardware devices...

‚úÖ Found: OAK-D Lite (USB 3.0)
‚úÖ Found: PCA9685 16-Channel PWM at I2C address 0x40
‚úÖ Found: Desktop Monitor

Using detected OAK-D Lite
‚úÖ Device connected: OAK-D-LITE
OAK-D started: baseline=7.50cm
‚úÖ OAK-D camera initialized
Using detected PCA9685 16-Channel PWM at 0x40
Arm moved to default safe positions
‚úÖ PCA9685 initialized at 0x40
‚úÖ Arm controller initialized
üéôÔ∏è  Using mock microphone capture
‚úÖ Microphone capture initialized
‚úÖ Episode recorder ready
üõû Initializing drivetrain controller...
‚úÖ Drivetrain controller ready at 0x40 using steering=servo[0], throttle=continuous_servo[1]
‚úÖ Drivetrain ready (REAL MODE)
üéÆ Initializing mode manager...
ü§ñ Activating AUTONOMOUS mode (motion + inference + training enabled)
============================================================
ü§ñ Mode Change: idle ‚Üí autonomous
============================================================
Time: 2025-12-08 10:46:21
Motion: Enabled
Recording: ON
Inference: ON
Self-Training: OFF

Mode Configuration:
  control_source: vla_policy
  startup_time: 2025-12-08 10:46:21
  auto_activated: True
  self_training_enabled: True
============================================================

‚úÖ Mode manager ready
üß† Initializing HOPE brain...
  Available memory: 4170MB
  Using development config (medium memory mode)
DEBUG_CMS_INIT: d_s=64, d_e=64, d_k=16, d_c=64, num_levels=2, cms_dims=[32, 64]
INFO:continuonbrain.resource_monitor:Registered cleanup callback for critical threshold
  ‚úì Registered with web monitoring
  ‚úì HOPE brain ready (587,105 parameters, 2.2MB)
============================================================
‚úÖ Brain Service Ready
============================================================
üöÄ Server listening on http://0.0.0.0:8080
INFO:continuonbrain.services.brain_service:HOPE confidence for 'what do you see?...': 0.10
INFO:continuonbrain.gemma_chat:Loading Gemma model: google/gemma-3n-E2B-it
INFO:continuonbrain.gemma_chat:Accelerate available: 1.12.0
INFO:accelerate.utils.modeling:Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - cpu: 8053070852 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 28212.81it/s]
ERROR:continuonbrain.gemma_chat:Failed to load Gemma model: You are trying to offload the whole model to the disk. Please use the `disk_offload` function instead.
INFO:continuonbrain.services.experience_logger:Logged conversation: 'what do you see?...' -> llm_with_hope_context
INFO:continuonbrain.services.brain_service:HOPE confidence for 'what do you see?...': 0.10
INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cpu
INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2
INFO:continuonbrain.services.experience_logger:Loaded sentence-transformers model for semantic search
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.32it/s]Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  4.28it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 10.85it/s]
INFO:continuonbrain.gemma_chat:Loading Gemma model: google/gemma-3n-E2B-it
INFO:continuonbrain.gemma_chat:Accelerate available: 1.12.0
INFO:accelerate.utils.modeling:Based on the current allocation process, no modules could be assigned to the following devices due to insufficient memory:
  - cpu: 8053070852 bytes required
These minimum requirements are specific to this allocation attempt and may vary. Consider increasing the available memory for these devices to at least the specified minimum, or adjusting the model config.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 45923.04it/s]
ERROR:continuonbrain.gemma_chat:Failed to load Gemma model: You are trying to offload the whole model to the disk. Please use the `disk_offload` function instead.
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.38it/s]Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  6.31it/s]
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 12.78it/s]
INFO:continuonbrain.services.experience_logger:Skipping duplicate conversation: 'what do you see?...'
