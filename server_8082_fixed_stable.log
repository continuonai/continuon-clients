DEBUG: CMS MODULE LOADED FROM /home/craigm26/Downloads/ContinuonXR/continuonbrain/hope_impl/cms.py
[DEBUG] server_routes imported from: /home/craigm26/Downloads/ContinuonXR/continuonbrain/server/routes.py
  Detected Hailo AI HAT+ (1 device(s)) - enabling offloading
  CONTINUON_PREFER_JAX=1 and JAX detected -> Enforcing JAX chat init.
JAX not available - install with: pip install jax jaxlib flax
JAX or transformers not available - cannot create GemmaChatJAX
HUGGINGFACE_TOKEN not set - gated models will not be accessible
  [Startup] Pre-loading model checkpoints...
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:05<00:10,  5.01s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:58<00:33, 33.75s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 19.14s/it]Loading checkpoint shards: 100%|██████████| 3/3 [01:00<00:00, 20.21s/it]
  [Startup] Model load result: True
 Model selected: JAX CoreModel (backend=jax)
  Failed to start status endpoint: [Errno 98] Address already in use
Initializing Robot Service (MOCK MODE)...

 Initializing episode recorder...
Using MOCK hardware mode
  Using mock microphone capture
Microphone capture initialized
 Episode recorder ready
  Skipping arm/drivetrain init (skip-motion-hw). Motion will stay mock.
 Initializing mode manager...
============================================================
 Mode Change: idle -> autonomous
============================================================
Time: 2025-12-15 06:43:44
Motion: Enabled
Recording: ON
Inference: ON
Self-Training: OFF

Mode Configuration:
  control_source: vla_policy
  restored_from_persisted: True
============================================================

 Mode manager ready
 Chat-learn scheduler: Merged into autonomous supervisor (independent thread disabled).
 HOPE autonomous learner supervisor started (thread; mode-gated)
Resource level changed: normal -> warning: WARNING: Memory at 95.4% - 374MB available
 Autonomy orchestrator started (thread; resource-aware)

============================================================
 Robot Service Ready (MOCK MODE)
============================================================

Web UI: http://localhost:8082/ui
API Endpoint: http://localhost:8082/status
Resource level changed: warning -> normal: Normal: 522MB available (93.5% used)
DEBUG_CMS_INIT: d_s=128, d_e=128, d_k=32, d_c=128, num_levels=3, cms_dims=[64, 128, 256]
[DEBUG Auto] mode=autonomous, want_run=True, chat_enabled=True, due=True, rec=False
[UnifiedAgent] Pausing Controller for Chat Session...
[UnifiedAgent] Starting Chat Learning Session...
[DEBUG] RunChatLearn called. Turns=20, Model=hope-v1, Delegate=google/gemma-370m
[DEBUG] RunChatLearn: Starting loop for 20 turns. LogRLDS=True
[DEBUG] Loop 0: History=0, Outputs=0
[ChatAdapter] chat() called with model_hint=hope-v1 delegate=google/gemma-370m
Ignoring model_hint=google/gemma-370m because it is not present in local HF cache (/home/craigm26/.cache/huggingface/hub) and downloads are disabled.
CMS compaction failed: 'NoneType' object has no attribute 'params'
[ChatAdapter] chat() called with model_hint=None delegate=None
